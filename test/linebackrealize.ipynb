{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.4800, -0.5458],\n        [-0.2173,  0.3229],\n        [ 1.1786,  0.3650],\n        ...,\n        [ 0.8490,  0.0331],\n        [-0.0378, -1.0917],\n        [ 0.5931,  0.2381]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  6.9974],\n        [  2.6643],\n        [  5.3202],\n        [ 10.4746],\n        [  4.3283],\n        [ 11.6752],\n        [  7.5350],\n        [  3.4997],\n        [ -1.2930],\n        [  4.6363],\n        [  6.4003],\n        [  2.1129],\n        [  1.8244],\n        [  3.8602],\n        [  4.8866],\n        [  5.3784],\n        [  7.4922],\n        [  6.2122],\n        [  0.7620],\n        [  7.5248],\n        [  7.9775],\n        [ -5.5303],\n        [  5.2356],\n        [ -0.8251],\n        [  0.0765],\n        [  2.4810],\n        [  3.6074],\n        [  2.3474],\n        [  6.1652],\n        [  6.0962],\n        [  3.0775],\n        [  3.8717],\n        [  5.4308],\n        [  0.3516],\n        [  7.3299],\n        [  8.1655],\n        [  2.8600],\n        [  3.3230],\n        [  0.1948],\n        [  5.8133],\n        [  4.5020],\n        [  2.2072],\n        [  2.2383],\n        [  1.8807],\n        [  6.7311],\n        [ -0.2809],\n        [  1.2389],\n        [  0.8892],\n        [  6.1512],\n        [  7.2067],\n        [  3.9286],\n        [  2.4938],\n        [  7.0962],\n        [  5.1997],\n        [ -0.0899],\n        [  7.4678],\n        [  6.5276],\n        [ 14.5227],\n        [  6.1394],\n        [  3.4065],\n        [  5.4556],\n        [-10.3615],\n        [  3.1527],\n        [  2.4497],\n        [  0.6240],\n        [  1.0844],\n        [ 10.1501],\n        [ -1.8809],\n        [ -1.3362],\n        [  3.2219],\n        [  0.1648],\n        [  6.9999],\n        [  4.7323],\n        [ -0.1433],\n        [  3.5750],\n        [  3.9439],\n        [  4.1976],\n        [  1.4502],\n        [  3.2509],\n        [  2.6933],\n        [  5.3238],\n        [  5.9105],\n        [  1.0823],\n        [  7.1434],\n        [  7.8075],\n        [ 11.0302],\n        [  5.9626],\n        [ -1.4905],\n        [  2.0299],\n        [  6.6691],\n        [  5.2291],\n        [ -2.6189],\n        [  9.7747],\n        [  5.5985],\n        [  1.4186],\n        [  5.8619],\n        [  5.3661],\n        [  1.2800],\n        [  0.2289],\n        [  4.1359],\n        [ -5.8119],\n        [  7.8117],\n        [  4.7412],\n        [  1.1070],\n        [  0.6974],\n        [  1.8104],\n        [  7.4223],\n        [  3.7612],\n        [  1.4341],\n        [  0.2674],\n        [  6.3079],\n        [  1.2155],\n        [  1.7899],\n        [ 10.7586],\n        [  4.8477],\n        [  3.7188],\n        [  8.2393],\n        [  9.3633],\n        [  7.1872],\n        [  5.4852],\n        [ 12.0206],\n        [  7.2487],\n        [ 10.3946],\n        [  9.7762],\n        [  3.7530],\n        [  0.1662],\n        [  2.2162],\n        [  9.5805],\n        [  7.0176],\n        [  1.4183],\n        [  6.7135],\n        [  1.8689],\n        [  8.8878],\n        [  3.4095],\n        [  6.5635],\n        [  2.5625],\n        [ -5.9441],\n        [ -0.5272],\n        [  0.5211],\n        [  8.8113],\n        [  3.8084],\n        [  6.2568],\n        [  1.3723],\n        [  6.6965],\n        [  8.5042],\n        [  4.8352],\n        [ -1.0109],\n        [ -0.1648],\n        [  5.2867],\n        [  7.7056],\n        [  7.4723],\n        [  5.6277],\n        [  0.1761],\n        [  5.9853],\n        [  7.4495],\n        [ 10.3203],\n        [  4.4707],\n        [  4.8635],\n        [  6.8949],\n        [  2.8934],\n        [ -1.3011],\n        [  6.6608],\n        [ -0.2772],\n        [  9.5839],\n        [  1.1816],\n        [  5.3830],\n        [ 12.2114],\n        [  8.4981],\n        [  9.3537],\n        [  9.5110],\n        [  0.4313],\n        [  4.5960],\n        [  1.4293],\n        [ -4.0210],\n        [  4.8191],\n        [  4.1582],\n        [  6.4042],\n        [ 13.7548],\n        [  5.0191],\n        [  3.7602],\n        [  1.1130],\n        [  6.8890],\n        [  5.6174],\n        [ -1.0506],\n        [  7.5686],\n        [ 10.1455],\n        [  4.5417],\n        [  4.4156],\n        [  6.2824],\n        [  3.5612],\n        [  3.3640],\n        [  1.1413],\n        [  5.3438],\n        [  5.2246],\n        [  2.8853],\n        [  4.8637],\n        [  4.0849],\n        [  1.3952],\n        [  3.9001],\n        [  2.5792],\n        [ 12.1427],\n        [  3.4304],\n        [  8.0525],\n        [  7.9823],\n        [  7.2789],\n        [  7.6143],\n        [  5.8137],\n        [  5.8942],\n        [  4.7558],\n        [ 11.4622],\n        [ 19.3586],\n        [ 10.2124],\n        [  6.5927],\n        [  4.1737],\n        [  0.6778],\n        [  3.0914],\n        [  3.4897],\n        [  3.3348],\n        [  2.4002],\n        [ -0.9679],\n        [ -0.3599],\n        [  0.2835],\n        [  1.0902],\n        [  2.1971],\n        [  7.4644],\n        [  5.9068],\n        [  0.9937],\n        [  9.6839],\n        [  2.6490],\n        [  3.9181],\n        [  4.9839],\n        [  9.8474],\n        [  8.8306],\n        [  2.7019],\n        [  9.8208],\n        [  4.6973],\n        [  9.9466],\n        [ -0.4804],\n        [  4.0037],\n        [  1.8143],\n        [  9.8395],\n        [  7.6805],\n        [  1.6200],\n        [  1.7797],\n        [  6.2933],\n        [ -4.6955],\n        [  1.2106],\n        [  5.7633],\n        [  3.2776],\n        [  4.5158],\n        [  9.3795],\n        [  5.4298],\n        [  7.4337],\n        [  2.5955],\n        [  9.8587],\n        [  5.8668],\n        [  9.4122],\n        [  8.5098],\n        [  4.3932],\n        [  5.1636],\n        [  5.2235],\n        [ -1.1867],\n        [  4.3474],\n        [ -2.9299],\n        [  4.8103],\n        [  4.8303],\n        [  7.0707],\n        [  9.8861],\n        [  5.2157],\n        [ 12.3442],\n        [  9.4266],\n        [  5.0341],\n        [  7.4969],\n        [ -0.0674],\n        [  1.6581],\n        [ 10.0795],\n        [  6.7580],\n        [  8.8922],\n        [  2.6537],\n        [  3.7214],\n        [  0.8479],\n        [  5.4915],\n        [ -5.4709],\n        [  8.0946],\n        [  0.4089],\n        [ 13.9525],\n        [  3.9495],\n        [ -2.4486],\n        [ -0.4707],\n        [  5.9803],\n        [  6.6360],\n        [  8.5764],\n        [  0.2728],\n        [  2.6741],\n        [  1.0490],\n        [ -3.3087],\n        [ 14.0250],\n        [  2.3258],\n        [  1.8230],\n        [ 10.0245],\n        [  2.7362],\n        [  2.4996],\n        [ -2.2212],\n        [  3.6183],\n        [  4.8022],\n        [  7.9095],\n        [  3.6236],\n        [  2.0795],\n        [ -0.5517],\n        [  4.3259],\n        [  1.1303],\n        [  1.4097],\n        [  2.2568],\n        [  3.9126],\n        [  7.6430],\n        [ 10.3410],\n        [ 14.5054],\n        [  3.3268],\n        [  0.4347],\n        [  5.4588],\n        [  0.3635],\n        [  7.9216],\n        [  5.1470],\n        [  4.8622],\n        [  5.7751],\n        [  2.6742],\n        [  4.9996],\n        [  2.9780],\n        [  5.9359],\n        [  4.1738],\n        [  2.0009],\n        [  3.8849],\n        [  4.9610],\n        [ -2.5433],\n        [  6.5799],\n        [  7.2507],\n        [  0.7330],\n        [  3.2545],\n        [  1.5178],\n        [ -1.9372],\n        [  6.5244],\n        [  8.4192],\n        [  6.6377],\n        [ -1.7946],\n        [  2.6415],\n        [  2.9005],\n        [  6.1109],\n        [  3.0890],\n        [  0.8588],\n        [ 10.0129],\n        [ -0.6286],\n        [  0.4069],\n        [  4.8029],\n        [  8.5238],\n        [  5.9147],\n        [  1.7877],\n        [  2.7415],\n        [ -0.8678],\n        [  1.1600],\n        [ -2.2367],\n        [  4.0970],\n        [  8.5280],\n        [  1.3616],\n        [  7.7316],\n        [ -1.5828],\n        [  1.0574],\n        [  8.3257],\n        [  6.7673],\n        [  5.7843],\n        [ 11.3244],\n        [ -3.6218],\n        [  2.9574],\n        [  3.1945],\n        [  2.7482],\n        [  3.6222],\n        [  2.4643],\n        [  5.0302],\n        [ -0.6375],\n        [  3.6885],\n        [ -2.4148],\n        [ -1.2792],\n        [ -0.8991],\n        [  7.7332],\n        [  5.1058],\n        [  4.0311],\n        [ -0.9911],\n        [  2.4739],\n        [  8.2786],\n        [  2.7202],\n        [  6.3115],\n        [  1.4059],\n        [  4.0260],\n        [  2.2243],\n        [  3.0391],\n        [  9.3293],\n        [  4.3190],\n        [ -4.3808],\n        [  4.8601],\n        [  7.9411],\n        [  4.0321],\n        [  8.5886],\n        [  3.2103],\n        [ -4.4213],\n        [  2.5902],\n        [ -0.4880],\n        [  7.3297],\n        [  4.0686],\n        [ -4.5994],\n        [ -0.1689],\n        [  1.9541],\n        [  6.7865],\n        [ 14.3843],\n        [  8.5153],\n        [  3.6142],\n        [  9.5790],\n        [  6.7521],\n        [  3.0057],\n        [  8.3873],\n        [  5.4077],\n        [  2.0436],\n        [ -1.0080],\n        [  5.6128],\n        [  3.6949],\n        [  2.6506],\n        [  7.7867],\n        [  3.7192],\n        [  3.0067],\n        [  2.8258],\n        [  8.5341],\n        [ -0.5602],\n        [  7.6908],\n        [ -0.0991],\n        [  5.8912],\n        [ 11.5802],\n        [  6.0828],\n        [  0.4073],\n        [  0.6259],\n        [  7.0192],\n        [ 10.5563],\n        [ -1.3060],\n        [  5.9379],\n        [  5.9084],\n        [  7.2301],\n        [ -0.5981],\n        [ -0.2241],\n        [  4.0715],\n        [  4.0921],\n        [  0.8856],\n        [  7.8558],\n        [  6.3968],\n        [ -1.0229],\n        [  4.9142],\n        [  9.1066],\n        [ -2.1267],\n        [ -0.9515],\n        [  4.2120],\n        [  8.4992],\n        [  5.1604],\n        [  0.4418],\n        [  7.2601],\n        [ 13.1461],\n        [ -2.3683],\n        [  6.4511],\n        [ 11.3207],\n        [  4.6553],\n        [  7.5554],\n        [  4.1392],\n        [  4.6224],\n        [  3.9196],\n        [  0.6277],\n        [  5.8538],\n        [  3.4651],\n        [  9.7343],\n        [  9.1249],\n        [  2.6287],\n        [  5.4608],\n        [ -3.6789],\n        [  3.2921],\n        [  3.9249],\n        [  5.6864],\n        [  4.9881],\n        [  3.6231],\n        [  1.3445],\n        [  1.8373],\n        [  3.8346],\n        [  3.6873],\n        [ -1.7303],\n        [  4.5902],\n        [ 10.5721],\n        [  5.7602],\n        [ 11.9039],\n        [  1.2280],\n        [ -2.2698],\n        [ -1.6129],\n        [  8.9844],\n        [  4.3375],\n        [  8.8827],\n        [  8.1715],\n        [  5.6136],\n        [  7.5223],\n        [  5.3589],\n        [ -3.8665],\n        [  6.9318],\n        [  4.3292],\n        [  3.9933],\n        [  0.6099],\n        [  0.1938],\n        [  0.5397],\n        [  5.3027],\n        [ 11.8239],\n        [  5.2335],\n        [  5.1829],\n        [  7.8787],\n        [  5.1523],\n        [  3.9943],\n        [  8.4840],\n        [  4.1743],\n        [  7.0191],\n        [ 16.9988],\n        [  9.1144],\n        [  3.8861],\n        [  5.5324],\n        [  0.1584],\n        [  5.3123],\n        [ -1.7863],\n        [  1.0633],\n        [  0.7142],\n        [  5.8873],\n        [ -4.6669],\n        [  6.5624],\n        [  9.4439],\n        [  5.0869],\n        [  6.2044],\n        [  5.2029],\n        [ -1.1866],\n        [  3.9649],\n        [  6.5623],\n        [  5.6389],\n        [  2.8473],\n        [  4.2074],\n        [  6.5115],\n        [ -0.7083],\n        [ -1.2139],\n        [ -2.3056],\n        [  4.5168],\n        [  7.4903],\n        [  5.8071],\n        [  4.3041],\n        [  5.6193],\n        [  2.7799],\n        [  1.1816],\n        [  0.7523],\n        [  1.5312],\n        [  6.1087],\n        [  6.5782],\n        [  4.0445],\n        [  7.9627],\n        [  5.4040],\n        [  5.3930],\n        [ 10.4791],\n        [ -1.6226],\n        [  3.8404],\n        [  1.7848],\n        [  4.9609],\n        [  4.8562],\n        [  5.5513],\n        [  1.8057],\n        [  2.7046],\n        [ 12.0441],\n        [  7.7507],\n        [  8.0047],\n        [ 12.8144],\n        [  3.0664],\n        [  1.7039],\n        [  4.8939],\n        [ -1.4685],\n        [  7.5299],\n        [  4.3957],\n        [  1.3166],\n        [  2.5506],\n        [  5.2464],\n        [  0.8028],\n        [  2.8830],\n        [  7.1963],\n        [  1.0091],\n        [  3.7032],\n        [  4.7375],\n        [  3.7961],\n        [  9.8641],\n        [ 13.3574],\n        [ -6.5252],\n        [  1.8921],\n        [  1.1911],\n        [  1.1374],\n        [  3.3849],\n        [  4.7800],\n        [  1.6130],\n        [  6.8590],\n        [  4.1243],\n        [  1.4739],\n        [  4.7723],\n        [  6.3089],\n        [  5.3304],\n        [  3.0451],\n        [ -1.4033],\n        [  4.0173],\n        [  8.8923],\n        [  2.9276],\n        [  7.2599],\n        [  4.2631],\n        [  8.3758],\n        [  5.8785],\n        [  6.3450],\n        [  4.0206],\n        [  1.7140],\n        [  8.6965],\n        [  7.5956],\n        [  8.2198],\n        [ -0.6951],\n        [  1.4521],\n        [  7.3387],\n        [  3.1032],\n        [ -0.3546],\n        [ 10.6879],\n        [  3.6654],\n        [  4.7653],\n        [  5.6400],\n        [  3.1825],\n        [  2.6007],\n        [  5.5626],\n        [  4.6873],\n        [  4.6456],\n        [ -1.2975],\n        [  1.3211],\n        [ -0.6028],\n        [  5.6858],\n        [  0.2149],\n        [ 13.8153],\n        [ -0.7499],\n        [  3.9467],\n        [  7.5008],\n        [ -0.2134],\n        [  2.0015],\n        [ -0.3272],\n        [  5.3997],\n        [  0.5673],\n        [  4.3196],\n        [ -6.3087],\n        [  4.5290],\n        [  7.5465],\n        [ -0.3047],\n        [  5.3991],\n        [ -3.1384],\n        [  9.6090],\n        [  7.6537],\n        [  6.0753],\n        [ 11.2420],\n        [  4.7467],\n        [  5.9417],\n        [ -0.6103],\n        [  4.9549],\n        [  4.5263],\n        [  5.3082],\n        [  5.0069],\n        [  3.7311],\n        [  5.5882],\n        [  0.9438],\n        [  1.2412],\n        [  2.8136],\n        [ 10.4347],\n        [ -0.7511],\n        [  5.3412],\n        [  5.2205],\n        [  4.9138],\n        [  2.6014],\n        [ -1.9947],\n        [ -1.1726],\n        [  4.4155],\n        [  4.8418],\n        [  2.5003],\n        [ -2.5152],\n        [ -2.6763],\n        [  5.0951],\n        [  7.1227],\n        [ 10.7314],\n        [  6.3093],\n        [  7.8462],\n        [  5.9369],\n        [  4.0326],\n        [  5.4484],\n        [ 10.2348],\n        [  4.1619],\n        [ -0.4836],\n        [  2.5231],\n        [  4.6684],\n        [  1.6594],\n        [  6.2780],\n        [  8.9632],\n        [  5.8539],\n        [  3.7471],\n        [  5.9749],\n        [ -1.6714],\n        [  1.9338],\n        [  8.9496],\n        [ -5.3914],\n        [  9.4790],\n        [  1.9252],\n        [  0.6741],\n        [  0.4723],\n        [  0.4075],\n        [  1.4192],\n        [  3.4343],\n        [  0.7213],\n        [  3.6827],\n        [ -0.8223],\n        [  6.7577],\n        [  3.4140],\n        [  2.2957],\n        [  8.0968],\n        [  1.5412],\n        [ -0.6169],\n        [ -1.2476],\n        [  8.3031],\n        [  5.7149],\n        [  0.5079],\n        [ -1.7663],\n        [ -0.7206],\n        [  7.4882],\n        [  9.1930],\n        [  5.4755],\n        [ 10.2771],\n        [  2.8999],\n        [  9.3274],\n        [ -1.9043],\n        [  7.9210],\n        [  6.4076],\n        [  7.1274],\n        [  5.1632],\n        [ 11.1843],\n        [ -2.0194],\n        [  3.3544],\n        [ 11.2363],\n        [  5.0465],\n        [  6.0543],\n        [  7.5566],\n        [  7.4467],\n        [  1.0830],\n        [ -4.3871],\n        [  1.7595],\n        [  3.7807],\n        [ -0.3541],\n        [  7.3360],\n        [  6.9467],\n        [  1.5070],\n        [  2.1581],\n        [ -0.8016],\n        [ 10.9051],\n        [  6.3811],\n        [  5.4242],\n        [  1.7403],\n        [  3.7336],\n        [ -2.2577],\n        [ 16.1356],\n        [  6.0324],\n        [  5.3950],\n        [  2.1314],\n        [  5.8248],\n        [ 10.8344],\n        [  1.9382],\n        [  4.8140],\n        [  5.5119],\n        [ -4.7502],\n        [  0.8413],\n        [ 17.1576],\n        [  6.0499],\n        [  7.7435],\n        [  7.5842],\n        [ -6.1838],\n        [  7.2743],\n        [ 11.8211],\n        [  6.0158],\n        [  4.8761],\n        [  4.7409],\n        [  3.8698],\n        [  0.9463],\n        [  5.6522],\n        [  0.5017],\n        [  3.3789],\n        [  6.9051],\n        [ -2.9181],\n        [  2.2968],\n        [  2.7570],\n        [ -3.1188],\n        [  2.4700],\n        [  4.3350],\n        [  3.4093],\n        [  1.8667],\n        [  1.5926],\n        [ 11.2758],\n        [  2.8181],\n        [  3.6810],\n        [  9.6403],\n        [  7.2669],\n        [  5.6404],\n        [  6.2456],\n        [  2.8494],\n        [  6.1933],\n        [  8.1330],\n        [  1.2991],\n        [ 14.6676],\n        [  3.7489],\n        [ -1.0852],\n        [  2.0096],\n        [  3.3085],\n        [  7.3947],\n        [  9.8194],\n        [  3.1985],\n        [  3.9478],\n        [  6.5368],\n        [  0.6415],\n        [  0.5245],\n        [ 10.3479],\n        [  1.6445],\n        [ -1.0775],\n        [ -2.8897],\n        [  2.7377],\n        [ -2.6130],\n        [  3.0835],\n        [  0.6244],\n        [ -0.5762],\n        [ -0.1312],\n        [  3.3054],\n        [ 11.6453],\n        [  3.4004],\n        [  8.8610],\n        [ -1.4894],\n        [  9.8139],\n        [  4.9982],\n        [  8.4104],\n        [  5.9745],\n        [  2.8574],\n        [  0.4431],\n        [  5.0660],\n        [  4.7125],\n        [  4.6620],\n        [  5.6797],\n        [ 10.8326],\n        [ -0.8258],\n        [  7.2777],\n        [  5.4394],\n        [  4.0725],\n        [  3.1635],\n        [ -1.7520],\n        [ 11.3927],\n        [ -3.1446],\n        [  7.3769],\n        [  0.8041],\n        [  2.1853],\n        [  0.4268],\n        [  4.5813],\n        [  3.6214],\n        [  6.3445],\n        [  4.5577],\n        [  0.4844],\n        [-11.4307],\n        [  9.1244],\n        [  9.9628],\n        [  4.6726],\n        [  1.7508],\n        [  6.4272],\n        [ -3.3747],\n        [  2.9015],\n        [ 10.5134],\n        [  5.9953],\n        [  6.0459],\n        [  1.4758],\n        [  3.6606],\n        [  7.7108],\n        [  7.2648],\n        [  0.8991],\n        [ 11.6671],\n        [ 11.9411],\n        [ -4.6950],\n        [  1.8587],\n        [  7.7931],\n        [  1.9552],\n        [  2.8990],\n        [  9.5456],\n        [ -2.5852],\n        [  4.5001],\n        [  3.6508],\n        [  3.7972],\n        [  2.9269],\n        [ -1.2984],\n        [  3.6225],\n        [  1.3167],\n        [  1.6188],\n        [  5.3923],\n        [ -4.0371],\n        [ -2.3757],\n        [  5.4095],\n        [  3.9981],\n        [ 11.2704],\n        [  5.6733],\n        [  7.7447],\n        [  9.8469],\n        [  9.8877],\n        [  8.4479],\n        [  6.1788],\n        [ 13.1169],\n        [  3.8681],\n        [  3.3821],\n        [  7.3099],\n        [ -2.3844],\n        [  5.9365],\n        [  2.3297],\n        [ -0.1376],\n        [  2.7171],\n        [  7.1980],\n        [  1.6658],\n        [ -5.2733],\n        [  3.8051],\n        [  3.5770],\n        [ 12.4917],\n        [  6.0624],\n        [  4.6733],\n        [  2.6581],\n        [  6.2698],\n        [  3.3907],\n        [  3.6441],\n        [  7.0746],\n        [  3.9881],\n        [  5.3024],\n        [  3.1236],\n        [ -0.2582],\n        [  4.2981],\n        [  2.6518],\n        [  1.9391],\n        [  5.8115],\n        [  2.2793],\n        [  4.7918],\n        [  6.7444],\n        [  2.6166],\n        [  9.2546],\n        [  7.9955],\n        [  1.0664],\n        [  3.9138],\n        [  3.8862],\n        [  6.1557],\n        [  5.9037],\n        [  9.0894],\n        [  3.7010],\n        [ 11.1033],\n        [  5.3699],\n        [  5.2394],\n        [  1.2156],\n        [  4.6859],\n        [  2.0864],\n        [  3.7365],\n        [  5.6294],\n        [  5.0706],\n        [  5.0081],\n        [  7.7638],\n        [  2.6918],\n        [ 10.8074],\n        [ -1.6993],\n        [  3.6224],\n        [  2.7656],\n        [ -4.5429],\n        [  3.1112],\n        [  6.0355],\n        [  1.6403],\n        [  4.3551],\n        [  8.9313],\n        [  5.6477],\n        [  8.0353],\n        [  7.1078],\n        [  8.7846],\n        [  1.8829],\n        [  6.3374],\n        [  9.3518],\n        [  3.3991],\n        [ -0.1759],\n        [  2.2459],\n        [  1.6540],\n        [  3.0697],\n        [ 10.2973],\n        [  4.9260],\n        [  5.9195],\n        [  7.2692],\n        [  3.3312],\n        [ 10.6862],\n        [ -2.9571],\n        [  2.9947],\n        [  9.5685],\n        [  6.8227],\n        [  0.6763],\n        [  5.7790],\n        [  7.8346],\n        [  4.5718]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9674, -2.5416],\n",
      "        [-0.3901,  1.2503],\n",
      "        [ 1.3921, -1.2513],\n",
      "        [-2.1671, -1.7554],\n",
      "        [-0.7855, -0.3180],\n",
      "        [-1.0078, -0.1054],\n",
      "        [-0.3904,  0.5863],\n",
      "        [-0.0839,  0.0892],\n",
      "        [ 0.6120,  0.9185],\n",
      "        [-0.8260, -1.2800]]) \n",
      " tensor([[10.9051],\n",
      "        [-0.8016],\n",
      "        [11.2420],\n",
      "        [ 5.8248],\n",
      "        [ 3.7010],\n",
      "        [ 2.5231],\n",
      "        [ 1.4186],\n",
      "        [ 3.7336],\n",
      "        [ 2.2957],\n",
      "        [ 6.9051]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def linreg(X, w, b):  #@save\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):  #@save\n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  #@save\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.035916\n",
      "epoch 2, loss 0.000125\n",
      "epoch 3, loss 0.000051\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y)  # X和y的小批量损失\n",
    "        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n",
    "        # 并以此计算关于[w,b]的梯度\n",
    "        l.sum().backward()\n",
    "        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的估计误差: tensor([ 0.0001, -0.0002], grad_fn=<SubBackward0>)\n",
      "b的估计误差: tensor([0.0007], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'b的估计误差: {true_b - b}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}